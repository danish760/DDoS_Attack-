{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpoKdrT4U6_R",
        "outputId": "891503e9-1cdc-430a-b2c0-0b9a6d1d36aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Data loaded successfully. Here are the first few rows:\n",
            "   flow_duration  Header_Length  Protocol Type  Duration        Rate  \\\n",
            "0       0.000000          54.00           6.00     64.00  855.456659   \n",
            "1       4.095609         162.00           6.00     64.00    0.918304   \n",
            "2       0.000000          54.00           6.00     64.00   14.317743   \n",
            "3       0.000000          54.00           6.00     64.00    2.968096   \n",
            "4       3.353060       33439.52           8.12     64.91  116.204060   \n",
            "\n",
            "        Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  ...  \\\n",
            "0  855.456659    0.0              0.0              0.0              0.0  ...   \n",
            "1    0.918304    0.0              0.0              1.0              0.0  ...   \n",
            "2   14.317743    0.0              0.0              0.0              0.0  ...   \n",
            "3    2.968096    0.0              0.0              0.0              0.0  ...   \n",
            "4  116.204060    0.0              0.0              0.0              0.0  ...   \n",
            "\n",
            "          Std  Tot size           IAT  Number   Magnitue      Radius  \\\n",
            "0    0.000000      54.0  8.331388e+07     9.5  10.392305    0.000000   \n",
            "1    0.000000      54.0  8.336199e+07     9.5  10.392305    0.000000   \n",
            "2    0.000000      54.0  8.307206e+07     9.5  10.392305    0.000000   \n",
            "3    0.000000      54.0  8.294637e+07     9.5  10.392305    0.000000   \n",
            "4  415.092008     577.6  8.297299e+07     9.5  24.925008  585.399563   \n",
            "\n",
            "      Covariance  Variance  Weight                    label  \n",
            "0       0.000000      0.00  141.55        DDoS-PSHACK_Flood  \n",
            "1       0.000000      0.00  141.55  DDoS-SynonymousIP_Flood  \n",
            "2       0.000000      0.00  141.55           DDoS-TCP_Flood  \n",
            "3       0.000000      0.00  141.55            DoS-TCP_Flood  \n",
            "4  322730.801967      0.95  141.55            DoS-SYN_Flood  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and Concatenate Data\n",
        "cyber_files = [f'/content/drive/My Drive/Cyber Security/data/cyber ({i}).csv' for i in range(1, 10)]\n",
        "cyber_dfs = [pd.read_csv(file) for file in cyber_files]\n",
        "\n",
        "combined_cyber_df = pd.concat(cyber_dfs, ignore_index=True)\n",
        "print(\"Data loaded successfully. Here are the first few rows:\")\n",
        "print(combined_cyber_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4oBkJAbVKrt",
        "outputId": "12359bbe-02ff-4649-c6d6-67655e32de6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            "flow_duration      0\n",
            "Header_Length      0\n",
            "Protocol Type      0\n",
            "Duration           0\n",
            "Rate               0\n",
            "Srate              0\n",
            "Drate              0\n",
            "fin_flag_number    0\n",
            "syn_flag_number    0\n",
            "rst_flag_number    0\n",
            "psh_flag_number    0\n",
            "ack_flag_number    0\n",
            "ece_flag_number    0\n",
            "cwr_flag_number    0\n",
            "ack_count          0\n",
            "syn_count          0\n",
            "fin_count          0\n",
            "urg_count          0\n",
            "rst_count          0\n",
            "HTTP               0\n",
            "HTTPS              0\n",
            "DNS                0\n",
            "Telnet             0\n",
            "SMTP               0\n",
            "SSH                0\n",
            "IRC                0\n",
            "TCP                0\n",
            "UDP                0\n",
            "DHCP               0\n",
            "ARP                0\n",
            "ICMP               0\n",
            "IPv                0\n",
            "LLC                0\n",
            "Tot sum            0\n",
            "Min                0\n",
            "Max                0\n",
            "AVG                0\n",
            "Std                0\n",
            "Tot size           0\n",
            "IAT                0\n",
            "Number             0\n",
            "Magnitue           0\n",
            "Radius             0\n",
            "Covariance         0\n",
            "Variance           0\n",
            "Weight             0\n",
            "label              0\n",
            "dtype: int64\n",
            "\n",
            "Handling missing values...\n",
            "\n",
            "Missing values after handling:\n",
            "flow_duration      0\n",
            "Header_Length      0\n",
            "Protocol Type      0\n",
            "Duration           0\n",
            "Rate               0\n",
            "Srate              0\n",
            "Drate              0\n",
            "fin_flag_number    0\n",
            "syn_flag_number    0\n",
            "rst_flag_number    0\n",
            "psh_flag_number    0\n",
            "ack_flag_number    0\n",
            "ece_flag_number    0\n",
            "cwr_flag_number    0\n",
            "ack_count          0\n",
            "syn_count          0\n",
            "fin_count          0\n",
            "urg_count          0\n",
            "rst_count          0\n",
            "HTTP               0\n",
            "HTTPS              0\n",
            "DNS                0\n",
            "Telnet             0\n",
            "SMTP               0\n",
            "SSH                0\n",
            "IRC                0\n",
            "TCP                0\n",
            "UDP                0\n",
            "DHCP               0\n",
            "ARP                0\n",
            "ICMP               0\n",
            "IPv                0\n",
            "LLC                0\n",
            "Tot sum            0\n",
            "Min                0\n",
            "Max                0\n",
            "AVG                0\n",
            "Std                0\n",
            "Tot size           0\n",
            "IAT                0\n",
            "Number             0\n",
            "Magnitue           0\n",
            "Radius             0\n",
            "Covariance         0\n",
            "Variance           0\n",
            "Weight             0\n",
            "label              0\n",
            "dtype: int64\n",
            "\n",
            "Missing values handled.\n",
            "Encoding categorical variables and scaling features...\n",
            "Dataset split into training and testing sets.\n",
            "Saving preprocessed data to disk...\n",
            "Preprocessing completed successfully and data saved.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Handle Missing Values\n",
        "\n",
        "# Print missing values before handling\n",
        "print(\"Missing values before handling:\")\n",
        "print(combined_cyber_df.isnull().sum())\n",
        "\n",
        "# Separate numeric and categorical columns\n",
        "numeric_cols = combined_cyber_df.select_dtypes(include=[np.number]).columns\n",
        "categorical_cols = combined_cyber_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Handle missing values\n",
        "print(\"\\nHandling missing values...\")\n",
        "combined_cyber_df[numeric_cols] = combined_cyber_df[numeric_cols].fillna(combined_cyber_df[numeric_cols].mean())\n",
        "combined_cyber_df[categorical_cols] = combined_cyber_df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
        "\n",
        "# Print missing values after handling\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(combined_cyber_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values handled.\")\n",
        "\n",
        "# Encode Categorical Variables and Scale Features\n",
        "print(\"Encoding categorical variables and scaling features...\")\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    combined_cyber_df[col] = le.fit_transform(combined_cyber_df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "target_column = 'label'\n",
        "features = combined_cyber_df.drop(columns=[target_column])\n",
        "target = combined_cyber_df[target_column]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Split the Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
        "print(\"Dataset split into training and testing sets.\")\n",
        "\n",
        "# Save preprocessed data and encoders/scalers to disk\n",
        "print(\"Saving preprocessed data to disk...\")\n",
        "preprocessed_data = {\n",
        "    'X_train': X_train,\n",
        "    'X_test': X_test,\n",
        "    'y_train': y_train,\n",
        "    'y_test': y_test,\n",
        "    'scaler': scaler,\n",
        "    'label_encoders': label_encoders\n",
        "}\n",
        "\n",
        "with open('/content/drive/My Drive/Cyber Security/preprocessed_data.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessed_data, f)\n",
        "\n",
        "print(\"Preprocessing completed successfully and data saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho4COuJTwTr_",
        "outputId": "b08d07cf-f530-4ab6-f50e-778efa559bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting attacks...\n",
            "Attack detection completed.\n",
            "Number of 'positive to attack' instances: 51045\n",
            "Number of 'negative to attack' instances: 130\n",
            "\n",
            "Sample 'positive to attack' instances:\n",
            "     flow_duration  Header_Length  Protocol Type  Duration       Rate  \\\n",
            "31      249.558927        25967.6            6.0      62.5   2.418499   \n",
            "119      63.168725      4689454.0            6.0      64.0  70.770779   \n",
            "159     159.866273         2697.8            7.1      96.5  15.184579   \n",
            "208     107.736321       165767.4            5.9      67.2   8.975599   \n",
            "237      25.252158      1902243.7           11.5     138.9  54.121593   \n",
            "\n",
            "         Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  ...  \\\n",
            "31    2.418499    0.0              0.0              0.0              0.0  ...   \n",
            "119  70.770779    0.0              0.0              0.0              0.0  ...   \n",
            "159  15.184579    0.0              0.0              0.0              0.0  ...   \n",
            "208   8.975599    0.0              0.0              0.0              0.0  ...   \n",
            "237  54.121593    0.0              0.0              0.0              0.0  ...   \n",
            "\n",
            "            Std  Tot size           IAT  Number   Magnitue      Radius  \\\n",
            "31   212.826701     192.5  8.675814e-03     5.5  18.845302  300.982407   \n",
            "119    0.000000    1514.0  1.020694e-03     5.5  55.027266    0.000000   \n",
            "159   60.183871      91.7  1.665164e+08    13.5  13.421458   85.312791   \n",
            "208   51.975587      99.2  1.665179e+08    13.5  15.092978   73.569683   \n",
            "237    4.144490      61.6  8.078599e-03     5.5  10.893315    5.861193   \n",
            "\n",
            "       Covariance  Variance  Weight  label  \n",
            "31   58132.852744       0.8    38.5      1  \n",
            "119      0.000000       0.0    38.5      1  \n",
            "159   3771.811261       1.0   244.6      1  \n",
            "208   2710.912480       1.0   244.6      1  \n",
            "237     19.435761       0.9    38.5      1  \n",
            "\n",
            "[5 rows x 47 columns]\n",
            "\n",
            "Sample 'negative to attack' instances:\n",
            "       flow_duration  Header_Length  Protocol Type  Duration         Rate  \\\n",
            "5789       78.837103         7098.4            7.0      59.5     1.590062   \n",
            "13226     125.463937         4273.9           12.0     124.7    66.645944   \n",
            "14711       0.025358       229329.0            6.0     244.0  6053.568058   \n",
            "21272       2.912737         1168.2           12.2     152.8    14.892542   \n",
            "34850    1789.997758        11878.1            9.3     143.7     0.057730   \n",
            "\n",
            "             Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
            "5789      1.590062    0.0              0.0              0.0              0.0   \n",
            "13226    66.645944    0.0              0.0              0.0              0.0   \n",
            "14711  6053.568058    0.0              0.0              0.0              0.0   \n",
            "21272    14.892542    0.0              0.0              0.0              0.0   \n",
            "34850     0.057730    0.0              0.0              0.0              0.0   \n",
            "\n",
            "       ...         Std  Tot size           IAT  Number   Magnitue      Radius  \\\n",
            "5789   ...   31.612300      83.2  7.393909e-03     5.5  14.213621   44.706543   \n",
            "13226  ...   57.532263     132.1  1.676297e+08    13.5  15.907533   81.359339   \n",
            "14711  ...    0.000000    1494.0  1.676298e+08    13.5  54.662601    0.000000   \n",
            "21272  ...  123.221730     220.6  1.676299e+08    13.5  18.903305  174.694222   \n",
            "34850  ...   58.858049     106.5  7.345600e-02     5.5  17.255954   83.237852   \n",
            "\n",
            "         Covariance  Variance  Weight  label  \n",
            "5789    1133.795815       0.9    38.5      0  \n",
            "13226   3327.702814       1.0   244.6      0  \n",
            "14711      0.000000       0.0   244.6      0  \n",
            "21272  15299.636048       1.0   244.6      0  \n",
            "34850   3929.063553       0.9    38.5      0  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Detection Phase\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Detection: Predict if an instance is \"positive to attack\" or \"negative to attack\"\n",
        "print(\"Detecting attacks...\")\n",
        "rf_detector = RandomForestClassifier(random_state=42)\n",
        "rf_detector.fit(X_train, y_train)\n",
        "\n",
        "# Predict attack likelihood on the entire dataset\n",
        "attack_likelihood = rf_detector.predict(scaled_features)\n",
        "\n",
        "# Filter the dataset to include only \"positive to attack\" and \"negative to attack\" instances\n",
        "positive_attack_df = combined_cyber_df[attack_likelihood == 1]\n",
        "scaled_positive_features = scaled_features[attack_likelihood == 1]\n",
        "positive_attack_labels = target[attack_likelihood == 1]\n",
        "\n",
        "negative_attack_df = combined_cyber_df[attack_likelihood == 0]\n",
        "scaled_negative_features = scaled_features[attack_likelihood == 0]\n",
        "negative_attack_labels = target[attack_likelihood == 0]\n",
        "\n",
        "print(\"Attack detection completed.\")\n",
        "print(\"Number of 'positive to attack' instances:\", len(positive_attack_df))\n",
        "print(\"Number of 'negative to attack' instances:\", len(negative_attack_df))\n",
        "\n",
        "# Display some samples of \"positive to attack\" instances\n",
        "print(\"\\nSample 'positive to attack' instances:\")\n",
        "print(positive_attack_df.head(5))\n",
        "\n",
        "# Display some samples of \"negative to attack\" instances\n",
        "print(\"\\nSample 'negative to attack' instances:\")\n",
        "print(negative_attack_df.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngo7lHrqVaMR",
        "outputId": "0a0e1ea7-1951-41ad-a85d-1649bf9d3c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding labels to their original attack names...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e4b44b6ddfde>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positive_attack_df['label'] = label_encoder.inverse_transform(positive_attack_labels)\n",
            "<ipython-input-4-e4b44b6ddfde>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positive_attack_df['Detection'] = positive_attack_df.apply(detect_protocol_attack, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack detection and classification complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e4b44b6ddfde>:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positive_attack_df['Attack_Type'] = positive_attack_df.apply(classify_attack, axis=1)\n"
          ]
        }
      ],
      "source": [
        "# Decode Labels for Attack Names\n",
        "print(\"Decoding labels to their original attack names...\")\n",
        "original_attack_names = [\n",
        "    \"DDoS-PSHACK_Flood\", \"DDoS-SynonymousIP_Flood\", \"DDoS-TCP_Flood\",\n",
        "    \"DoS-TCP_Flood\", \"DoS-SYN_Flood\", \"DDoS-ICMP_Flood\", \"Mirai-greeth_flood\",\n",
        "    \"Mirai-greip_flood\", \"DDoS-UDP_Flood\", \"DDoS-RSTFINFlood\", \"DoS-UDP_Flood\",\n",
        "    \"DDoS-SYN_Flood\", \"DDoS-ICMP_Fragmentation\", \"BenignTraffic\",\n",
        "    \"MITM-ArpSpoofing\", \"Mirai-udpplain\", \"DDoS-ACK_Fragmentation\",\n",
        "    \"DNS_Spoofing\", \"DDoS-UDP_Fragmentation\", \"Recon-HostDiscovery\",\n",
        "    \"Recon-PingSweep\", \"Recon-OSScan\", \"DDoS-HTTP_Flood\", \"VulnerabilityScan\",\n",
        "    \"DoS-HTTP_Flood\", \"Recon-PortScan\", \"BrowserHijacking\",\n",
        "    \"DDoS-SlowLoris\", \"DictionaryBruteForce\", \"Backdoor_Malware\",\n",
        "    \"XSS\", \"SqlInjection\", \"CommandInjection\", \"Uploading_Attack\"\n",
        "]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(original_attack_names)\n",
        "positive_attack_df['label'] = label_encoder.inverse_transform(positive_attack_labels)\n",
        "\n",
        "# Detect and Classify TCP/UDP Attacks\n",
        "def detect_protocol_attack(row):\n",
        "    if 'UDP' in row['label']:\n",
        "        return 'UDP Attack'\n",
        "    elif 'TCP' in row['label']:\n",
        "        return 'TCP Attack'\n",
        "    else:\n",
        "        return 'Other/Unknown Attack'\n",
        "\n",
        "positive_attack_df['Detection'] = positive_attack_df.apply(detect_protocol_attack, axis=1)\n",
        "\n",
        "def classify_attack(row):\n",
        "    if row['Detection'] == 'UDP Attack':\n",
        "        if 'UDP_Flood' in row['label']:\n",
        "            return 'UDP Flood Attack'\n",
        "        elif 'UDP_Fragmentation' in row['label']:\n",
        "            return 'UDP Fragmentation Attack'\n",
        "        elif 'udpplain' in row['label']:\n",
        "            return 'Mirai UDP Plain Attack'\n",
        "        else:\n",
        "            return 'Other UDP Attack'\n",
        "    elif row['Detection'] == 'TCP Attack':\n",
        "        if 'SYN_Flood' in row['label']:\n",
        "            return 'TCP SYN Flood Attack'\n",
        "        elif 'PSHACK_Flood' in row['label']:\n",
        "            return 'TCP PSH ACK Flood Attack'\n",
        "        elif 'RSTFINFlood' in row['label']:\n",
        "            return 'TCP RST/FIN Flood Attack'\n",
        "        elif 'TCP_Flood' in row['label']:\n",
        "            return 'TCP Flood Attack'\n",
        "        elif 'ACK_Fragmentation' in row['label']:\n",
        "            return 'TCP ACK Fragmentation Attack'\n",
        "        else:\n",
        "            return 'Other TCP Attack'\n",
        "    else:\n",
        "        return 'Non-TCP/UDP or Unknown Attack'\n",
        "\n",
        "positive_attack_df['Attack_Type'] = positive_attack_df.apply(classify_attack, axis=1)\n",
        "print(\"Attack detection and classification complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDl3jCTj6S4L",
        "outputId": "020aa952-a178-40b4-c75f-b232a3ed7517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and testing data for positive attack detection defined.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already filtered your dataset to get the positive attack features and labels\n",
        "# Replace `scaled_positive_features` and `positive_attack_labels` with your actual variable names\n",
        "scaled_positive_features = X_train  # Replace with actual features after preprocessing\n",
        "positive_attack_labels = y_train  # Replace with actual labels after filtering for positive attacks\n",
        "\n",
        "# Split the filtered positive attack dataset into training and testing sets\n",
        "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(\n",
        "    scaled_positive_features, positive_attack_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training and testing data for positive attack detection defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_PpeHAHVnwn",
        "outputId": "e35059d6-ae07-4216-b31f-059a84364b3d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing and training machine learning models...\n",
            "Training AdaBoost...\n",
            "Performance of AdaBoost:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.81      0.51      0.62      8065\n",
            "           2       0.00      0.00      0.00        26\n",
            "           3       0.00      0.00      0.00        31\n",
            "           4       0.50      0.99      0.66      2089\n",
            "           5       0.00      0.00      0.00       218\n",
            "           6       0.97      1.00      0.98     52417\n",
            "           7       1.00      0.97      0.98      3313\n",
            "           8       1.00      0.97      0.99     29887\n",
            "           9       1.00      1.00      1.00     29372\n",
            "          10       0.66      0.96      0.78     29632\n",
            "          11       0.00      0.00      0.00       175\n",
            "          12       0.96      1.00      0.98     26195\n",
            "          13       0.60      1.00      0.75     33291\n",
            "          14       0.73      0.89      0.80     39772\n",
            "          15       0.00      0.00      0.00      2069\n",
            "          16       0.84      0.61      0.71      1342\n",
            "          17       0.50      0.01      0.02        98\n",
            "          18       0.00      0.00      0.00       519\n",
            "          19       0.00      0.00      0.00     14728\n",
            "          20       0.00      0.00      0.00     19465\n",
            "          21       0.24      0.09      0.13     24462\n",
            "          22       0.90      0.12      0.22      2259\n",
            "          23       0.56      0.99      0.72      7009\n",
            "          24       0.42      0.01      0.01      5460\n",
            "          25       0.52      0.97      0.68      6526\n",
            "          26       0.86      0.60      0.70       955\n",
            "          27       0.97      0.42      0.59       710\n",
            "          28       0.00      0.00      0.00        12\n",
            "          29       0.80      0.49      0.61       630\n",
            "          30       0.00      0.00      0.00        40\n",
            "          31       1.00      0.80      0.89         5\n",
            "          32       0.00      0.00      0.00       265\n",
            "          33       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.77    341068\n",
            "   macro avg       0.47      0.42      0.41    341068\n",
            "weighted avg       0.69      0.77      0.71    341068\n",
            "\n",
            "[[   0    0    0 ...    0    0    0]\n",
            " [   0 4081    0 ...    0    0    0]\n",
            " [   0   11    0 ...    0    0    0]\n",
            " ...\n",
            " [   0    0    0 ...    4    0    0]\n",
            " [   0    0    0 ...    0    0    0]\n",
            " [   0    0    0 ...    0    0    0]]\n",
            "Training K-Nearest Neighbors...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Convert y_test_pos to label format for confusion matrix and classification report\n",
        "# Ensure that y_test_pos is in one-hot encoded format before applying argmax\n",
        "if y_test_pos.ndim > 1:  # Check if it's one-hot encoded\n",
        "    y_test_labels = np.argmax(y_test_pos, axis=1)\n",
        "else:\n",
        "    y_test_labels = y_test_pos  # Already label encoded\n",
        "\n",
        "# Model Initialization and Training (Machine Learning Models)\n",
        "print(\"Initializing and training machine learning models...\")\n",
        "models = {\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"MLP Classifier\": MLPClassifier(max_iter=300)\n",
        "}\n",
        "\n",
        "evaluation_metrics = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    # Ensure y_train_pos is label encoded for model training\n",
        "    model.fit(X_train_pos, y_train_pos.argmax(axis=1) if y_train_pos.ndim > 1 else y_train_pos)\n",
        "    y_pred = model.predict(X_test_pos)\n",
        "\n",
        "    print(f\"Performance of {name}:\")\n",
        "    print(classification_report(y_test_labels, y_pred))\n",
        "    print(confusion_matrix(y_test_labels, y_pred))\n",
        "\n",
        "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "    precision = precision_score(y_test_labels, y_pred, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y_test_labels, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test_labels, y_pred, average='weighted')\n",
        "\n",
        "    # Check if the model supports probability predictions (not all classifiers do)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_prob = model.predict_proba(X_test_pos)\n",
        "        roc_auc = roc_auc_score(y_test_pos, y_prob, multi_class='ovr') if y_test_pos.ndim > 1 else \"N/A\"\n",
        "    else:\n",
        "        roc_auc = \"N/A\"  # ROC AUC is not applicable for models that don't support predict_proba\n",
        "\n",
        "    evaluation_metrics[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"ROC AUC\": roc_auc\n",
        "    }\n",
        "\n",
        "# Step 9: Visualization of Model Performance\n",
        "print(\"Visualizing model performance...\")\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test_pos)\n",
        "    cm = confusion_matrix(y_test_labels, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f'Confusion Matrix for {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC Curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, model in models.items():\n",
        "    if hasattr(model, \"predict_proba\"):  # Only plot ROC if model supports predict_proba\n",
        "        y_prob = model.predict_proba(X_test_pos)\n",
        "        if y_test_pos.ndim > 1:  # Ensure y_test_pos is one-hot encoded for roc_curve\n",
        "            fpr, tpr, _ = roc_curve(y_test_pos[:, 1], y_prob[:, 1], pos_label=1)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Step 10: Print Evaluation Metrics Summary\n",
        "metrics_df = pd.DataFrame(evaluation_metrics).T  # Transpose for better readability\n",
        "print(\"\\nPerformance metrics for all models:\")\n",
        "print(metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EfjAellkZZ9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Number of unique classes in the positive attack labels\n",
        "num_classes = len(np.unique(y_train_pos))\n",
        "\n",
        "# One-hot encode your labels for deep learning models\n",
        "y_train_pos = to_categorical(y_train_pos, num_classes=num_classes)\n",
        "y_test_pos = to_categorical(y_test_pos, num_classes=num_classes)\n",
        "\n",
        "evaluation_metrics = {}\n",
        "\n",
        "# Training CNN Model\n",
        "print(\"Training CNN model...\")\n",
        "X_train_cnn = X_train_pos.reshape(X_train_pos.shape[0], X_train_pos.shape[1], 1)\n",
        "X_test_cnn = X_test_pos.reshape(X_test_pos.shape[0], X_test_pos.shape[1], 1)\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')  # Multi-class output layer\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Multi-class loss\n",
        "cnn_model.fit(X_train_cnn, y_train_pos, epochs=10, batch_size=64, validation_data=(X_test_cnn, y_test_pos))\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test_pos)\n",
        "y_prob_cnn = cnn_model.predict(X_test_cnn)\n",
        "y_pred_cnn = np.argmax(y_prob_cnn, axis=1)  # Convert probabilities to class predictions\n",
        "\n",
        "evaluation_metrics['CNN'] = {\n",
        "    \"Accuracy\": cnn_accuracy,\n",
        "    \"Precision\": precision_score(y_test_pos.argmax(axis=1), y_pred_cnn, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test_pos.argmax(axis=1), y_pred_cnn, average='weighted'),\n",
        "    \"F1 Score\": f1_score(y_test_pos.argmax(axis=1), y_pred_cnn, average='weighted'),\n",
        "    \"ROC AUC\": roc_auc_score(y_test_pos, y_prob_cnn, multi_class='ovr')  # Use 'ovr' or 'ovo'\n",
        "}\n",
        "\n",
        "# Print CNN Evaluation Metrics\n",
        "print(\"\\nCNN Evaluation Metrics:\")\n",
        "for metric, value in evaluation_metrics['CNN'].items():\n",
        "    print(f\"{metric}: {value}\")\n",
        "\n",
        "# Training LSTM Model\n",
        "print(\"\\nTraining LSTM model...\")\n",
        "X_train_lstm = X_train_pos.reshape((X_train_pos.shape[0], 1, X_train_pos.shape[1]))\n",
        "X_test_lstm = X_test_pos.reshape((X_test_pos.shape[0], 1, X_test_pos.shape[1]))\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(1, X_train_pos.shape[1])),\n",
        "    Dense(num_classes, activation='softmax')  # Multi-class output layer\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train_lstm, y_train_pos, epochs=10, batch_size=64, validation_data=(X_test_lstm, y_test_pos))\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test_pos)\n",
        "y_prob_lstm = lstm_model.predict(X_test_lstm)\n",
        "y_pred_lstm = np.argmax(y_prob_lstm, axis=1)  # Convert probabilities to class predictions\n",
        "\n",
        "evaluation_metrics['LSTM'] = {\n",
        "    \"Accuracy\": lstm_accuracy,\n",
        "    \"Precision\": precision_score(y_test_pos.argmax(axis=1), y_pred_lstm, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test_pos.argmax(axis=1), y_pred_lstm, average='weighted'),\n",
        "    \"F1 Score\": f1_score(y_test_pos.argmax(axis=1), y_pred_lstm, average='weighted'),\n",
        "    \"ROC AUC\": roc_auc_score(y_test_pos, y_prob_lstm, multi_class='ovr')\n",
        "}\n",
        "\n",
        "# Print LSTM Evaluation Metrics\n",
        "print(\"\\nLSTM Evaluation Metrics:\")\n",
        "for metric, value in evaluation_metrics['LSTM'].items():\n",
        "    print(f\"{metric}: {value}\")\n",
        "\n",
        "# Training DNN Model\n",
        "print(\"\\nTraining DNN model...\")\n",
        "dnn_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_pos.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')  # Multi-class output layer\n",
        "])\n",
        "\n",
        "dnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "dnn_model.fit(X_train_pos, y_train_pos, epochs=10, batch_size=64, validation_data=(X_test_pos, y_test_pos))\n",
        "dnn_loss, dnn_accuracy = dnn_model.evaluate(X_test_pos, y_test_pos)\n",
        "y_prob_dnn = dnn_model.predict(X_test_pos)\n",
        "y_pred_dnn = np.argmax(y_prob_dnn, axis=1)  # Convert probabilities to class predictions\n",
        "\n",
        "evaluation_metrics['DNN'] = {\n",
        "    \"Accuracy\": dnn_accuracy,\n",
        "    \"Precision\": precision_score(y_test_pos.argmax(axis=1), y_pred_dnn, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test_pos.argmax(axis=1), y_pred_dnn, average='weighted'),\n",
        "    \"F1 Score\": f1_score(y_test_pos.argmax(axis=1), y_pred_dnn, average='weighted'),\n",
        "    \"ROC AUC\": roc_auc_score(y_test_pos, y_prob_dnn, multi_class='ovr')\n",
        "}\n",
        "\n",
        "# Print DNN Evaluation Metrics\n",
        "print(\"\\nDNN Evaluation Metrics:\")\n",
        "for metric, value in evaluation_metrics['DNN'].items():\n",
        "    print(f\"{metric}: {value}\")\n",
        "\n",
        "# Visualization of Model Performance\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curve(y_true, y_prob, model_name):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1], pos_label=1)  # Adjust pos_label if needed\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# CNN Model Visualization\n",
        "print(\"\\nVisualizing CNN model performance...\")\n",
        "plot_confusion_matrix(y_test_pos.argmax(axis=1), y_pred_cnn, \"CNN\")\n",
        "plot_roc_curve(y_test_pos.argmax(axis=1), y_prob_cnn, \"CNN\")\n",
        "\n",
        "# LSTM Model Visualization\n",
        "print(\"\\nVisualizing LSTM model performance...\")\n",
        "plot_confusion_matrix(y_test_pos.argmax(axis=1), y_pred_lstm, \"LSTM\")\n",
        "plot_roc_curve(y_test_pos.argmax(axis=1), y_prob_lstm, \"LSTM\")\n",
        "\n",
        "# DNN Model Visualization\n",
        "print(\"\\nVisualizing DNN model performance...\")\n",
        "plot_confusion_matrix(y_test_pos.argmax(axis=1), y_pred_dnn, \"DNN\")\n",
        "plot_roc_curve(y_test_pos.argmax(axis=1), y_prob_dnn, \"DNN\")\n",
        "\n",
        "print(\"\\nAll models have been trained and evaluated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy3ZGpXgqcAE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to display all the metrics for all models\n",
        "metrics_df = pd.DataFrame(evaluation_metrics).T  # Transpose for better readability\n",
        "\n",
        "# Print the DataFrame as a table\n",
        "print(\"\\nPerformance metrics for all models:\")\n",
        "print(metrics_df)\n",
        "\n",
        "# Sort the DataFrame by a specific metric (e.g., F1 Score)\n",
        "sorted_metrics_df = metrics_df.sort_values(by=\"F1 Score\", ascending=False)\n",
        "print(\"\\nModels sorted by F1 Score:\")\n",
        "print(sorted_metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO7K5uyFmbEr"
      },
      "outputs": [],
      "source": [
        "# Selected 'best_model' is the MLP Classifier based on the evaluation metrics\n",
        "best_model = models['MLP Classifier']\n",
        "\n",
        "# Detecting and classifying attacks using the best model\n",
        "print(\"Detecting and classifying attacks with the best model...\")\n",
        "\n",
        "# Apply the best model to the test set\n",
        "y_pred = best_model.predict(X_test_pos)\n",
        "\n",
        "# Map predictions back to attack types (assuming `y_pred` is label encoded)\n",
        "predicted_attack_types = label_encoders['label'].inverse_transform(y_pred)\n",
        "\n",
        "# Display some predictions\n",
        "print(\"\\nSample attack detection results:\")\n",
        "for i in range(10):  # Display first 10 results\n",
        "    actual_label = label_encoders['label'].inverse_transform([y_test_pos[i].argmax()])[0]  # Convert one-hot to label\n",
        "    print(f\"Predicted: {predicted_attack_types[i]}, Actual: {actual_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}